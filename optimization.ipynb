{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd1c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 0) 데이터 예시 =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "import warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.model_selection\")\n",
    "\n",
    "# 예시용: 숫자 + 범주 혼합 데이터 구성\n",
    "X_num, y = make_classification(n_samples=2000, n_features=6, n_informative=4, random_state=42)\n",
    "df_num = pd.DataFrame(X_num, columns=[f\"num{i}\" for i in range(X_num.shape[1])])\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "df_cat = pd.DataFrame({\n",
    "    \"cat0\": rng.choice([\"A\",\"B\",\"C\",\"D\",\"E\"], size=len(df_num)),\n",
    "    # \"cat1\": rng.choice([\"X\",\"Y\",\"Z\"], size=len(df_num)),\n",
    "})\n",
    "X_df = pd.concat([df_num, df_cat], axis=1)\n",
    "\n",
    "num_cols = [c for c in X_df.columns if c.startswith(\"num\")]\n",
    "cat_cols = [c for c in X_df.columns if c.startswith(\"cat\")]\n",
    "\n",
    "# ===== 1) 전처리 파이프라인 =====\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=True, with_std=True), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# ===== 2) 앙상블(스태킹) 정의 =====\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "base_estimators = [\n",
    "    (\"svm\", SVC(probability=True, kernel=\"rbf\", random_state=42)),\n",
    "    (\"rf\", RandomForestClassifier(random_state=42)),\n",
    "    (\"hgb\", HistGradientBoostingClassifier(random_state=42)),\n",
    "]\n",
    "\n",
    "final_estimator = LogisticRegression(max_iter=1000, n_jobs=-1, random_state=42)\n",
    "# StackingClassifier는 순차적 연결이 아니라, 병렬 base 모델들의 예측을 meta 모델 입력으로 쓰는 구조\n",
    "stacking = StackingClassifier(\n",
    "    estimators=base_estimators,\n",
    "    final_estimator=final_estimator,\n",
    "    passthrough=False,           # 원본 특성까지 최종기에 넣으려면 True\n",
    "    stack_method=\"auto\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"clf\", stacking),\n",
    "])\n",
    "\n",
    "# ===== 3) 하이퍼파라미터 탐색 공간 =====\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa: F401\n",
    "from sklearn.model_selection import HalvingRandomSearchCV, StratifiedKFold, KFold\n",
    "from scipy.stats import loguniform, randint\n",
    "\n",
    "param_dist = {\n",
    "    # SVM (RBF)\n",
    "    \"clf__svm__C\": loguniform(1e-2, 1e2),\n",
    "    \"clf__svm__gamma\": loguniform(1e-4, 1e0),\n",
    "\n",
    "    # RandomForest\n",
    "    \"clf__rf__n_estimators\": randint(100, 600),\n",
    "    \"clf__rf__max_depth\": randint(3, 20),\n",
    "    \"clf__rf__min_samples_split\": randint(2, 10),\n",
    "\n",
    "    # HistGradientBoosting\n",
    "    \"clf__hgb__learning_rate\": loguniform(1e-2, 3e-1),\n",
    "    \"clf__hgb__max_depth\": randint(3, 20),\n",
    "    \"clf__hgb__l2_regularization\": loguniform(1e-6, 1e-1),\n",
    "\n",
    "    # 최종 로지스틱\n",
    "    \"clf__final_estimator__C\": loguniform(1e-2, 1e2),\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "search = HalvingRandomSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_distributions=param_dist,\n",
    "    factor=3,                   # 샘플/파라미터 줄여가는 속도\n",
    "    random_state=42,\n",
    "    cv=cv,\n",
    "    scoring=\"roc_auc_ovo_weighted\",\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "search.fit(X_df, y)\n",
    "\n",
    "print(\"best score:\", search.best_score_)\n",
    "print(\"best params:\")\n",
    "for k, v in search.best_params_.items():\n",
    "    print(\"  \", k, \"=\", v)\n",
    "\n",
    "best_model = search.best_estimator_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
